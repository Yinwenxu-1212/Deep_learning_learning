{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d469a8",
   "metadata": {},
   "source": [
    "# Pytorch基础操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb6c9ee",
   "metadata": {},
   "source": [
    "## 1. 基础语法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88d7032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b3698a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0+cu118'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e450c356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5050, 0.7070, 0.9993],\n",
       "        [0.5795, 0.0153, 0.7702],\n",
       "        [0.1581, 0.5423, 0.8336],\n",
       "        [0.5369, 0.9946, 0.5457],\n",
       "        [0.2589, 0.7079, 0.9123]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ca6012",
   "metadata": {},
   "source": [
    "Pytorch的基本数据单元是tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa489e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1d310fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.5000, 3.0000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fac563e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7133e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1,8)\n",
    "print(x.size(),y.size(),z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7652982",
   "metadata": {},
   "source": [
    "## 2. Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984e4180",
   "metadata": {},
   "source": [
    "### 2.1 初始化Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83c4f24",
   "metadata": {},
   "source": [
    "**1. 直接从原生数据创建**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e57e69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1,2], [3,4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c06ded",
   "metadata": {},
   "source": [
    "**2. 从NumPy数组创建**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46a79fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np_array = np.array(data)\n",
    "np_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c71d201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], dtype=torch.int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np = torch.from_numpy(np_array)\n",
    "x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c982416f",
   "metadata": {},
   "source": [
    "**3. 从tensor变量创建**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3475e5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "\n",
      "Random Tensor:\n",
      "tensor([[0.9335, 0.3193],\n",
      "        [0.8964, 0.8951]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # ones_like创建继承x_data属性的新张量，且所有元素为1\n",
    "print(f\"Ones Tensor: \\n{x_ones}\\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # 创建一个新的张量，其形状与x_data相同，但是填充了随机数\n",
    "print(f\"Random Tensor:\\n{x_rand}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbd7d2d",
   "metadata": {},
   "source": [
    "**4. 从随机数据或常量创建**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7153062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape 是 tensor 维数的元组。在下面的实例中，它决定了输出 tensor 的维数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d21f09b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor:\n",
      "tensor([[0.2172, 0.6897, 0.4017],\n",
      "        [0.3227, 0.9929, 0.4083]])\n",
      "\n",
      "Ones Tensor:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "Zeros Tensor:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor:\\n{rand_tensor}\\n\")\n",
    "print(f\"Ones Tensor:\\n{ones_tensor}\\n\")\n",
    "print(f\"Zeros Tensor:\\n{zeros_tensor}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a176020a",
   "metadata": {},
   "source": [
    "### 2.2 Tensor的属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78178750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor 属性描述了它们的形状、数据类型和存储它们的设备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96c453ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4470b064",
   "metadata": {},
   "source": [
    "### 2.3 Tensor的操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32dd360",
   "metadata": {},
   "source": [
    "**1. 索引和分片的标准操作**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fa5fea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9693, 0.5596, 0.2732, 0.0790],\n",
      "        [0.4292, 0.0833, 0.0558, 0.8595],\n",
      "        [0.6236, 0.8381, 0.6848, 0.2082],\n",
      "        [0.8773, 0.3311, 0.0300, 0.7743]])\n",
      "First row:\n",
      "tensor([0.9693, 0.5596, 0.2732, 0.0790])\n",
      "\n",
      "First column:\n",
      "tensor([0.9693, 0.4292, 0.6236, 0.8773])\n",
      "\n",
      "Last column:\n",
      "tensor([0.0790, 0.8595, 0.2082, 0.7743])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(4,4)\n",
    "print(tensor[:,:])\n",
    "# 第一行\n",
    "first_row = tensor[0]\n",
    "# 第一列\n",
    "first_column = tensor[ : ,0]\n",
    "# 最后一列\n",
    "last_column = tensor[ : ,-1]\n",
    "print(f\"First row:\\n{first_row}\\n\")\n",
    "print(f\"First column:\\n{first_column}\\n\")\n",
    "print(f\"Last column:\\n{last_column}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e469dbc",
   "metadata": {},
   "source": [
    "**2. 连接 tensors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4887a489",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cat 将一系列tensor沿着给定的维数连接起来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e187e1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.ones(4,4)\n",
    "tensor2 = torch.zeros(4,4)\n",
    "print(tensor1[:,:])\n",
    "print(tensor2[:,:])\n",
    "# 张量按照行并排起来\n",
    "t1 = torch.cat([tensor1, tensor2],dim=1)\n",
    "print(t1)\n",
    "# 张量按照列并排起来\n",
    "t2 = torch.cat([tensor1, tensor2],dim=0)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f7ecca",
   "metadata": {},
   "source": [
    "**3. 算术运算**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06ebeabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "Y1=tensor([[2., 2.],\n",
      "        [2., 2.]])\n",
      "\n",
      "Y2=tensor([[2., 2.],\n",
      "        [2., 2.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(2,2)\n",
    "print(tensor)\n",
    "# tensor.T returns the transpose of a tensor\n",
    "# @可以用于矩阵相乘，matmul()当两个tensor都为n>=2的矩阵时，表示矩阵相乘\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "print(f\"Y1={y1}\\n\")\n",
    "print(f\"Y2={y2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a729765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor3=tensor([[21, 24, 27]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1 = [[1,2]]\n",
    "data2 = [[5,6,7],[8,9,10]]\n",
    "tensor1 = torch.tensor(data1)\n",
    "tensor2 = torch.tensor(data2)\n",
    "tensor3 = tensor1.matmul(tensor2)\n",
    "print(f\"Tensor3={tensor3}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11e58e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y3=tensor([[0.3574, 0.8434],\n",
      "        [0.3876, 0.5467]])\n",
      "\n",
      "Y3'=tensor([[2., 2.],\n",
      "        [2., 2.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y3 = torch.rand_like(y1)\n",
    "print(f\"Y3={y3}\\n\")\n",
    "torch.matmul(tensor, tensor.T, out=y3) # torch.matmul(input, other, *, out=None) → Tensor\n",
    "# input和other是要进行乘法运算的两个张量，out是可选参数，用于指定输出张量。这里就将运算结果输出到y3\n",
    "print(f\"Y3'={y3}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c1756cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z1=tensor([[ 1,  4,  9],\n",
      "        [16, 25, 36]])\n",
      "\n",
      "Z2=tensor([[ 1,  4,  9],\n",
      "        [16, 25, 36]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# * 可以用来表示矩阵对应位置元素相乘；mul()函数也可以这样用\n",
    "data_z = [[1,2,3],[4,5,6]]\n",
    "tensor_z = torch.tensor(data_z)\n",
    "z1 = tensor_z * tensor_z\n",
    "z2 = tensor_z.mul(tensor_z)\n",
    "print(f\"Z1={z1}\\n\")\n",
    "print(f\"Z2={z2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9eb60b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z3=tensor([[0.7304, 0.4182, 0.9047],\n",
      "        [0.1997, 0.9050, 0.1450]])\n",
      "\n",
      "Z3'=tensor([[ 1.,  4.,  9.],\n",
      "        [16., 25., 36.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor_z = tensor_z.float()  # 确保 tensor_z 是浮点数\n",
    "z3 = torch.rand_like(tensor_z)\n",
    "print(f\"Z3={z3}\\n\")\n",
    "torch.mul(tensor_z, tensor_z, out=z3) # 将点乘的结果输出到z3\n",
    "print(f\"Z3'={z3}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4742332",
   "metadata": {},
   "source": [
    "**4. 单个元素的tensor**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481dca27",
   "metadata": {},
   "source": [
    "通过将 tensors 的所有值聚合成一个值，就可以使用 item() 将它转换成 Python 数值:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ddf356b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "4.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(tensor)\n",
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf49e50",
   "metadata": {},
   "source": [
    "### 2.4 Tensor与Numpy的转换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a52d3b1",
   "metadata": {},
   "source": [
    "**1. Tensor转换为Numpy数组**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3a65f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# .numpy()\n",
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2982eb9",
   "metadata": {},
   "source": [
    "**2. Numpy数组转换为Tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a5994067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# .from_numpy()\n",
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f26119",
   "metadata": {},
   "source": [
    "## 3. 自动求导机制Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8bd02e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2443,  1.2509,  0.1761,  2.3178],\n",
       "        [-1.3872, -1.8785,  0.0048,  0.4109],\n",
       "        [ 1.6161,  2.4497,  0.9768, -0.3773]], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3,4,requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bfe161",
   "metadata": {},
   "source": [
    "requires_grad 表达的含义是，这一参数是否保留（或者说持有，即在前向传播完成后，是否在显存中记录这一参数的梯度，而非立即释放）梯度，等待优化器执行optim.step()更新参数。\n",
    "\n",
    "当requires_grad = False，则不保留梯度，因此即便在optimizer中注册了参数，也没有梯度可以用来更新参数，因此参数不变。不过不影响梯度继续反向传播，即假设某一层（例如第三层）参数的requires_grad为False或True，前面层（第1或2层）参数的梯度都不变。\n",
    "\n",
    "当requires_grad = True，则在前向计算后保留梯度，用于optimizer更新参数。但如果没有在optimizer中注册参数，那么即便保存了梯度,也无法更新参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9ecd8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9841, -0.3123, -1.2117, -0.9480],\n",
       "        [ 0.2664,  0.1468, -1.0574,  0.3353],\n",
       "        [-0.0445, -1.2126,  0.1410,  1.8781]], requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.randn(3,4,requires_grad=True)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cf2ef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = b + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71410f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3127, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = t.sum()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6976d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标量对向量求导，直接调用backward（）函数，进行反向传播\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52f33b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
