---
date: 2025-01-03
tags:
  - attention
---
# 1. ATTENTION MODEL

## 1.1 基础

	问题实例 s 被定义为一个包含 n 个节点的图，
	每个节点 i 的特征为 xi ，在 TSP 中，xi​ 是节点的坐标。
	图是完全连接的，每两个节点之间都有边（包括自连接）。
	解决方案 π 被定义为节点的排列：π=(π1​,π2​,…,πn​),
	每个 πi 表示某个具体的节点，且节点不能重复访问.

注意力模型通过学习定义了一个 **随机策略**$$
p_\theta(\pi|s)
$$用于选择给定问题实例 s 的解 π 。

策略被分解为条件概率的乘积形式：$$ p_\theta(\pi|s) = \prod_{t=1}^n p_\theta(\pi_t|s, \pi_1:t-1)$$
## 1.2 Encoder

**Encoder（编码器）** 是一种用于将输入数据转化为高维特征表示的神经网络模块。它的目的是从输入数据中提取有意义的特征，同时压缩和重组输入信息，使其适合后续模块（如解码器或分类器）的处理。
![[Pasted image 20250103151128.png]]

![[Pasted image 20250103143346.png]]
### 1.2.1 输入节点特征（Node Input）

	红色节点表示输入特征 x1,x2,x3,x4
	每个节点的输入特征是原始数据， TSP 中的二维坐标 xi=(xi(1),xi(2))
	通过投影（绿色箭头）转化为初始嵌入 hi(0)
### 1.2.2 节点嵌入（Node Embedding）

	蓝色节点表示每个节点在某一层的嵌入
	初始嵌入 hi(0)​ 是从输入特征 xi​ 线性投影得到：

$$
h_i^{(0)}​=W^{x}x_i​ + b_x
$$

	嵌入的维度是 dh=128。
	在后续 N 层中，这些嵌入会不断更新。


### 1.2.3 多层更新（Attention Layers）

编码器的核心过程，分为 NNN 层，每层由两个子层组成。
#### 1.2.3.1 多头注意力层（MHA, Multi-Head Attention）

##### (1) 注意力机制
目的：计算节点之间的消息传递权重（Message Passing）
具体计算过程：
![[Pasted image 20250103144832.png]]
##### (2) 多头注意力机制

**多头自注意力机制中的多个并行注意力计算单元**。每个头都独立地执行自注意力计算，每个头有自己的一组 Q、K、V 权重矩阵。这些头的计算结果随后会被连接（或拼接）在一起，并通过一个线性变换得到最终输出。

![[Pasted image 20250103145754.png]]
$$
\hat{h}_i^{\ell}=\mathrm{BN}^{\ell}\left(h_i^{(\ell-1)}+\operatorname{MHA}^{\ell}\left(h_1^{(\ell-1)}, \ldots, h_n^{(\ell-1)}\right)\right)
$$
#### 1.2.3.2 前馈子层（Feed-Forward Sublayer）
![[Pasted image 20250103150256.png]]
$$
h_i^{\ell}=\mathrm{BN}^{\ell}\left(\hat{h}_i^{\ell}+\mathrm{FF}^{\ell}\left(\hat{h}_i^{\ell}\right)\right)
$$
#### 1.2.3.3 批归一化（Batch Normalization, BN）
![[Pasted image 20250103150352.png]]
## 1.3 Decoder
![[Pasted image 20250103151141.png]]
![[Pasted image 20250103151328.png]]
### 1.3.1 解码的目标

Decoder 的任务是逐步生成路径（Tour），即节点序列 π=(π1,π2,…,πn)。在时间步 t，解码器需要：

1. 基于编码器生成的节点嵌入和图嵌入；
2. 根据当前解码的上下文（context），选择下一个节点 πt\pi_tπt​；
3. 确保已访问节点不会被重复选择（通过掩码机制）。

### 1.3.2 解码的关键步骤

#### 1.3.2.1 上下文嵌入的计算
$$
解码器在每个时间步会构建一个特殊的 上下文节点嵌入 h_c^{(N)}​，作为当前解码状态的表示。
$$
#### 1.3.2.2 注意力权重的计算

![[Pasted image 20250103152929.png]]
#### 1.3.2.3 上下文嵌入的更新
![[Pasted image 20250103153721.png]]
#### 1.3.2.4 输出概率的计算
![[Pasted image 20250103153816.png]]
Softmax 将这些权重转化为 [0, 1] 区间内的数值，表示每个节点相对于其他节点被选中的可能性。