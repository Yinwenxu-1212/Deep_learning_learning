{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6f5a3bd",
   "metadata": {},
   "source": [
    "# 自动微分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bab3910",
   "metadata": {},
   "source": [
    "## 1.标量变量的反向传播（y=2x^2）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1693a423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# requires_grad 属性为 True，意味着 PyTorch 会追踪与这个张量相关的操作，允许计算该张量的梯度。\n",
    "x = torch.tensor([0,1,2,3], dtype=torch.float32, requires_grad = True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fcae2249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y=2xTx,且是个标量\n",
    "y = 2*torch.dot(x, x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c8d443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  4.,  8., 12.])\n"
     ]
    }
   ],
   "source": [
    "# 调用反向传播函数自动计算y关于x每个分量的梯度\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e7c43eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在默认情况，Pytorch会累积梯度，需要清楚之前的值\n",
    "x.grad.zero_()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5458f9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.sum()\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f404a5",
   "metadata": {},
   "source": [
    "## 2. 非标量变量的反向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3388c273",
   "metadata": {},
   "source": [
    "当y不是标量时，向量y关于向量x的导数的最自然解释是一个矩阵。 对于高阶和高维的y和x，求导的结果可以是一个高阶张量。\n",
    "\n",
    "然而，虽然这些更奇特的对象确实出现在高级机器学习中（包括[深度学习中]）， 但当调用向量的反向计算时，我们通常会试图计算一批训练样本中每个组成部分的损失函数的导数。 这里(，我们的目的不是计算微分矩阵，而是单独计算批量中每个样本的偏导数之和。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5233d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "# 将x对应位置的元素平方得到新的张量\n",
    "y = x*x\n",
    "# 方法一：求和操作（sum()） 将一个张量中的所有元素加和，得到一个标量，从而允许反向传播。\n",
    "# 通过将输出张量求和，我们可以确保反向传播的结果仍然是有意义的（即每个元素都有对应的梯度）。\n",
    "y.sum().backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0d1dad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "# 将x对应位置的元素平方得到新的张量\n",
    "y = x*x\n",
    "# 方法二：为非标量的张量显式指定梯度\n",
    "# 为每个元素显式指定梯度（与 y 形状相同）\n",
    "gradients = torch.ones_like(y)\n",
    "# 反向传播\n",
    "y.backward(gradient=gradients)\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd7fd20",
   "metadata": {},
   "source": [
    "## 3. 分离计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd2f091",
   "metadata": {},
   "source": [
    "将某些计算移动到记录的计算图之外，用于将参数固定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "05364e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y = x * x\n",
    "u = y.detach() # 将y作为常数，而不是关于x的函数\n",
    "z = u * x\n",
    "\n",
    "z.sum().backward()\n",
    "x.grad == u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5f6d93",
   "metadata": {},
   "source": [
    "## 4. 控制流的梯度计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b4d9f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    b = a * 2\n",
    "    # b.norm() 计算张量 b 的范数（默认为 L2 范数，即平方和的平方根）。\n",
    "    while b.norm() < 1000:\n",
    "        b = b * 2\n",
    "    if b.sum() > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = b + 100\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b618e758",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(size=(), requires_grad = True)\n",
    "d = f(a)\n",
    "d.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a527a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 因为f在其输入a中是分段线性的，因此对于任意一个a，都存在某一个常量标量k，使得f(a)=ka，即f(a)对a求偏导为f(a)/a\n",
    "a.grad == d/a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
